{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: convert pdf to dataframe (sentence level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text tokenization with spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def split_sentences(text: str) -> list[str]:\n",
    "    # strip to avoid leading/trailing blanks\n",
    "    doc = nlp(text.strip())\n",
    "    return [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3 speaker patterns\n",
    "speaker_patterns = [\n",
    "    # 1. \"Name, Title\"\n",
    "    re.compile(\n",
    "        r'^(?=[A-Z][A-Za-z0-9 ]{3,20},\\s*[A-Z][A-Za-z ]{1,20}$)'\n",
    "        r'(?P<speaker>[A-Z][A-Za-z0-9 ]+,\\s*[A-Z][A-Za-z ]+)\\s*$',\n",
    "        re.MULTILINE\n",
    "    ),\n",
    "\n",
    "    # 2. \"Name:\"\n",
    "    re.compile(\n",
    "        r'^(?=[A-Z][A-Za-z0-9 ]{1,20}:)'\n",
    "        r'(?P<speaker>(?:[A-Z]{2,}|[A-Z][a-z]+)'\n",
    "        r'(?:\\s+(?:[A-Z]{2,}|[A-Z][a-z]+)){0,4}):',\n",
    "        re.MULTILINE\n",
    "    ),\n",
    "\n",
    "    # 3. \"Name, Title, Subtitle\"\n",
    "    re.compile(\n",
    "        r'^(?P<speaker>'                                \n",
    "        r'[A-Z][A-Za-z0-9]+(?:\\s+[A-Z][A-Za-z0-9]+)*'   \n",
    "        r'(?:'                                          \n",
    "          r',\\s*[A-Z][A-Za-z]+(?:\\s+[A-Za-z]+)*'        \n",
    "        r'){2,}'                                        \n",
    "        r')\\s*$',                                       \n",
    "        re.MULTILINE\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_speaker_matches(text):\n",
    "    matches = []\n",
    "    for pat in speaker_patterns:\n",
    "        matches.extend(pat.finditer(text))\n",
    "    return sorted(matches, key=lambda m: m.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quarter(filename: str) -> str:\n",
    "    m = re.search(r'-Q([1-4])-(\\d{4})-', filename)\n",
    "    if m:\n",
    "        quarter, year = m.group(1), m.group(2)\n",
    "        return f\"{year}Q{quarter}\"\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(speaker: str) -> str:\n",
    "    base = speaker.strip().rstrip(':').strip()\n",
    "    return base.split(',', 1)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_position(name: str) -> str:\n",
    "    position_map = {\n",
    "        \"Mark Zuckerberg\": \"CEO\",\n",
    "        \"Susan Li\": \"CFO\",\n",
    "        \"Kenneth Dorell\": \"Investor Relations Director\",\n",
    "        \"Operator\": \"Operator\",\n",
    "    }\n",
    "    return position_map.get(name, \"Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove page numbers from text\n",
    "def remove_page_numbers(page_text):\n",
    "    lines = page_text.splitlines()\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if not re.match(r'^\\s*(Page\\s*)?\\d+\\s*$', line):\n",
    "            cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transcript(pdf_path):\n",
    "    output = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Remove page numbers from each page\n",
    "        text = \"\\n\".join(\n",
    "            remove_page_numbers(page.extract_text() or \"\") for page in pdf.pages\n",
    "        )\n",
    "\n",
    "    matches = find_speaker_matches(text)\n",
    "    for idx, m in enumerate(matches):\n",
    "        raw_speaker = m.group('speaker').strip()\n",
    "        start = m.end()\n",
    "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(text)\n",
    "        block_text = text[start:end].replace(\"\\n\", \" \").strip()\n",
    "        sentences = [s for s in split_sentences(block_text) if s and len(s.split()) > 7]\n",
    "        output.append({\n",
    "            \"raw_speaker\": raw_speaker,\n",
    "            \"sentences\": sentences,\n",
    "        })\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_json_path):\n",
    "    all_records = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing {filename}...\")\n",
    "\n",
    "        quarter = extract_quarter(filename)\n",
    "        for block in extract_transcript(pdf_path):\n",
    "            raw = block[\"raw_speaker\"]\n",
    "            name = extract_name(raw)\n",
    "            pos  = extract_position(name)\n",
    "            all_records.append({\n",
    "                \"filename\": filename,\n",
    "                \"quarter\": quarter,\n",
    "                \"speaker\": name,       \n",
    "                \"position\": pos,\n",
    "                \"sentences\": block[\"sentences\"],\n",
    "            })\n",
    "\n",
    "    print(f\"Saving {len(all_records)} records to {output_json_path}...\")\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_records, f, indent=2, ensure_ascii=False)\n",
    "    print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing META-Q1-2024-Earnings-Call-Transcript.pdf...\n",
      "Processing META-Q1-2025-Earnings-Call-Transcript.pdf...\n",
      "Processing META-Q2-2024-Earnings-Call-Transcript.pdf...\n",
      "Processing META-Q3-2024-Earnings-Call-Transcript.pdf...\n",
      "Processing META-Q4-2024-Earnings-Call-Transcript.pdf...\n",
      "Saving 176 records to Earnings Call Transcript.json...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    folder = \"Earnings Call Transcript\"\n",
    "    output_file = \"Earnings Call Transcript.json\"\n",
    "    process_folder(folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Earnings Call Transcript.json\")\n",
    "df = df.explode(\"sentences\").rename(columns={\"sentences\": \"sentence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>quarter</th>\n",
       "      <th>speaker</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>META-Q1-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Good afternoon and welcome to Meta Platforms f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>META-Q1-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Joining me today to discuss our results are Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>META-Q1-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Before we get started, I would like to take th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>META-Q1-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Actual results may differ materially from thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>META-Q1-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Factors that could cause these results to diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>META-Q4-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>So the actual business opportunity for Meta AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>META-Q4-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>And I think that’s an important thing for us t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>META-Q4-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>But nonetheless, we’ve run a process like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>META-Q4-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Kenneth Dorell</td>\n",
       "      <td>Investor Relations Director</td>\n",
       "      <td>And we look forward to speaking with you again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>META-Q4-2024-Earnings-Call-Transcript.pdf</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1917 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      filename quarter          speaker  \\\n",
       "0    META-Q1-2024-Earnings-Call-Transcript.pdf  2024Q1       Ken Dorell   \n",
       "0    META-Q1-2024-Earnings-Call-Transcript.pdf  2024Q1       Ken Dorell   \n",
       "0    META-Q1-2024-Earnings-Call-Transcript.pdf  2024Q1       Ken Dorell   \n",
       "0    META-Q1-2024-Earnings-Call-Transcript.pdf  2024Q1       Ken Dorell   \n",
       "0    META-Q1-2024-Earnings-Call-Transcript.pdf  2024Q1       Ken Dorell   \n",
       "..                                         ...     ...              ...   \n",
       "173  META-Q4-2024-Earnings-Call-Transcript.pdf  2024Q4  Mark Zuckerberg   \n",
       "173  META-Q4-2024-Earnings-Call-Transcript.pdf  2024Q4  Mark Zuckerberg   \n",
       "173  META-Q4-2024-Earnings-Call-Transcript.pdf  2024Q4  Mark Zuckerberg   \n",
       "174  META-Q4-2024-Earnings-Call-Transcript.pdf  2024Q4   Kenneth Dorell   \n",
       "175  META-Q4-2024-Earnings-Call-Transcript.pdf  2024Q4         Operator   \n",
       "\n",
       "                        position  \\\n",
       "0                        Analyst   \n",
       "0                        Analyst   \n",
       "0                        Analyst   \n",
       "0                        Analyst   \n",
       "0                        Analyst   \n",
       "..                           ...   \n",
       "173                          CEO   \n",
       "173                          CEO   \n",
       "173                          CEO   \n",
       "174  Investor Relations Director   \n",
       "175                     Operator   \n",
       "\n",
       "                                              sentence  \n",
       "0    Good afternoon and welcome to Meta Platforms f...  \n",
       "0    Joining me today to discuss our results are Ma...  \n",
       "0    Before we get started, I would like to take th...  \n",
       "0    Actual results may differ materially from thos...  \n",
       "0    Factors that could cause these results to diff...  \n",
       "..                                                 ...  \n",
       "173  So the actual business opportunity for Meta AI...  \n",
       "173  And I think that’s an important thing for us t...  \n",
       "173  But nonetheless, we’ve run a process like this...  \n",
       "174  And we look forward to speaking with you again...  \n",
       "175                                                NaN  \n",
       "\n",
       "[1917 rows x 5 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence is assinged a unique ID to maintain traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = range(1, len(df) + 1)\n",
    "df.drop('filename', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id'] + [c for c in df.columns if c != 'id']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>speaker</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Good afternoon and welcome to Meta Platforms f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Joining me today to discuss our results are Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Before we get started, I would like to take th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Actual results may differ materially from thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Factors that could cause these results to diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1913</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>So the actual business opportunity for Meta AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1914</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>And I think that’s an important thing for us t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1915</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>But nonetheless, we’ve run a process like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1916</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Kenneth Dorell</td>\n",
       "      <td>Investor Relations Director</td>\n",
       "      <td>And we look forward to speaking with you again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1917</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1917 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id quarter          speaker                     position  \\\n",
       "0       1  2024Q1       Ken Dorell                      Analyst   \n",
       "0       2  2024Q1       Ken Dorell                      Analyst   \n",
       "0       3  2024Q1       Ken Dorell                      Analyst   \n",
       "0       4  2024Q1       Ken Dorell                      Analyst   \n",
       "0       5  2024Q1       Ken Dorell                      Analyst   \n",
       "..    ...     ...              ...                          ...   \n",
       "173  1913  2024Q4  Mark Zuckerberg                          CEO   \n",
       "173  1914  2024Q4  Mark Zuckerberg                          CEO   \n",
       "173  1915  2024Q4  Mark Zuckerberg                          CEO   \n",
       "174  1916  2024Q4   Kenneth Dorell  Investor Relations Director   \n",
       "175  1917  2024Q4         Operator                     Operator   \n",
       "\n",
       "                                              sentence  \n",
       "0    Good afternoon and welcome to Meta Platforms f...  \n",
       "0    Joining me today to discuss our results are Ma...  \n",
       "0    Before we get started, I would like to take th...  \n",
       "0    Actual results may differ materially from thos...  \n",
       "0    Factors that could cause these results to diff...  \n",
       "..                                                 ...  \n",
       "173  So the actual business opportunity for Meta AI...  \n",
       "173  And I think that’s an important thing for us t...  \n",
       "173  But nonetheless, we’ve run a process like this...  \n",
       "174  And we look forward to speaking with you again...  \n",
       "175                                                NaN  \n",
       "\n",
       "[1917 rows x 5 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>speaker</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Good afternoon and welcome to Meta Platforms f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Joining me today to discuss our results are Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Before we get started, I would like to take th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Actual results may differ materially from thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>Ken Dorell</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Factors that could cause these results to diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1912</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>This year, the improvements to the business ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1913</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>So the actual business opportunity for Meta AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1914</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>And I think that’s an important thing for us t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1915</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>But nonetheless, we’ve run a process like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1916</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>Kenneth Dorell</td>\n",
       "      <td>Investor Relations Director</td>\n",
       "      <td>And we look forward to speaking with you again...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1915 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id quarter          speaker                     position  \\\n",
       "0       1  2024Q1       Ken Dorell                      Analyst   \n",
       "0       2  2024Q1       Ken Dorell                      Analyst   \n",
       "0       3  2024Q1       Ken Dorell                      Analyst   \n",
       "0       4  2024Q1       Ken Dorell                      Analyst   \n",
       "0       5  2024Q1       Ken Dorell                      Analyst   \n",
       "..    ...     ...              ...                          ...   \n",
       "173  1912  2024Q4  Mark Zuckerberg                          CEO   \n",
       "173  1913  2024Q4  Mark Zuckerberg                          CEO   \n",
       "173  1914  2024Q4  Mark Zuckerberg                          CEO   \n",
       "173  1915  2024Q4  Mark Zuckerberg                          CEO   \n",
       "174  1916  2024Q4   Kenneth Dorell  Investor Relations Director   \n",
       "\n",
       "                                              sentence  \n",
       "0    Good afternoon and welcome to Meta Platforms f...  \n",
       "0    Joining me today to discuss our results are Ma...  \n",
       "0    Before we get started, I would like to take th...  \n",
       "0    Actual results may differ materially from thos...  \n",
       "0    Factors that could cause these results to diff...  \n",
       "..                                                 ...  \n",
       "173  This year, the improvements to the business ar...  \n",
       "173  So the actual business opportunity for Meta AI...  \n",
       "173  And I think that’s an important thing for us t...  \n",
       "173  But nonetheless, we’ve run a process like this...  \n",
       "174  And we look forward to speaking with you again...  \n",
       "\n",
       "[1915 rows x 5 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every earnings call is comprised of 2 parts: a prepared statement by the CEO and CFO, and a Q&A session with analysts. The prepared statement is usually structured and follows a script, while the Q&A session is more dynamic and can cover a wide range of topics.\n",
    "- In Meta's earnings call, the Q&A session starts with a specific marker: \"With that, Krista, let’s open up the call for questions.\" This marker is used to identify the beginning of the Q&A section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    quarter   speaker                                           sentence\n",
      "2    2024Q1  Susan Li  With that, Krista, let’s open up the call for ...\n",
      "37   2025Q1  Susan Li  With that, Krista, let’s open up the call for ...\n",
      "73   2024Q2  Susan Li  With that, Krista, let’s open up the call for ...\n",
      "109  2024Q3  Susan Li  With that, Krista, let’s open up the call for ...\n",
      "143  2024Q4  Susan Li  With that, Krista, let’s open up the call for ...\n"
     ]
    }
   ],
   "source": [
    "qna_marker = [\"With that, Krista, let’s open up the call for questions.\"]\n",
    "mask = df['sentence'].apply(lambda s: any(marker in s for marker in qna_marker))\n",
    "qna_sentences = df.loc[mask,['quarter', 'speaker', 'sentence']]\n",
    "print(qna_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then extract the ID of the sentences that act as a marker for the Q&A section in each earnings call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_id = qna_sentences.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new column call 'section', and assign the value 'Q&A' to the sentences that are part of the Q&A section, which are those sentences that come after the marker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thu\\AppData\\Local\\Temp\\ipykernel_20460\\3050683314.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['section'] = 'Presentation'\n"
     ]
    }
   ],
   "source": [
    "# Initialize all as Presentation first\n",
    "df['section'] = 'Presentation'\n",
    "\n",
    "# Dictionary mapping quarters to Q&A start indices\n",
    "qna_start_indices = {\n",
    "    '2024Q1': qna_id[0],\n",
    "    '2025Q1': qna_id[1],\n",
    "    '2024Q2': qna_id[2],\n",
    "    '2024Q3': qna_id[3],\n",
    "    '2024Q4': qna_id[4],\n",
    "}\n",
    "\n",
    "for quarter, start_idx in qna_start_indices.items():\n",
    "    mask = (df['quarter'] == quarter) & (df.index > start_idx)\n",
    "    df.loc[mask, 'section'] = 'Q&A'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>speaker</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>We will now open the lines for a question and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>To ask a question, please press star one on yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>To withdraw your question, again press star one.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Please pick up your handset before asking your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>If you are streaming today’s call, please mute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>But then as a bunch of the products start to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>And then at some point, just like the other pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>But -- that’s kind of where we’re at on it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>CEO</td>\n",
       "      <td>We’re definitely focused on doing the work mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2025Q1</td>\n",
       "      <td>Kenneth Dorell</td>\n",
       "      <td>Investor Relations Director</td>\n",
       "      <td>Thank you everyone for joining us today, and w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   quarter          speaker                     position  \\\n",
       "38  2025Q1         Operator                     Operator   \n",
       "38  2025Q1         Operator                     Operator   \n",
       "38  2025Q1         Operator                     Operator   \n",
       "38  2025Q1         Operator                     Operator   \n",
       "38  2025Q1         Operator                     Operator   \n",
       "..     ...              ...                          ...   \n",
       "69  2025Q1  Mark Zuckerberg                          CEO   \n",
       "69  2025Q1  Mark Zuckerberg                          CEO   \n",
       "69  2025Q1  Mark Zuckerberg                          CEO   \n",
       "69  2025Q1  Mark Zuckerberg                          CEO   \n",
       "70  2025Q1   Kenneth Dorell  Investor Relations Director   \n",
       "\n",
       "                                             sentence  \n",
       "38  We will now open the lines for a question and ...  \n",
       "38  To ask a question, please press star one on yo...  \n",
       "38   To withdraw your question, again press star one.  \n",
       "38  Please pick up your handset before asking your...  \n",
       "38  If you are streaming today’s call, please mute...  \n",
       "..                                                ...  \n",
       "69  But then as a bunch of the products start to h...  \n",
       "69  And then at some point, just like the other pr...  \n",
       "69        But -- that’s kind of where we’re at on it.  \n",
       "69  We’re definitely focused on doing the work mor...  \n",
       "70  Thank you everyone for joining us today, and w...  \n",
       "\n",
       "[192 rows x 4 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[df['section'] == 'Q&A'][['quarter','speaker','position','sentence']]\n",
    "df1[df1['quarter']  == '2025Q1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is necessary step for FinBERT and DeepSeek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import text-extracted dataset\n",
    "df = pd.read_csv(\"output.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two copies of the dataframe for FinBERT and LLM processing\n",
    "df_finbert = df\n",
    "df_llm = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all models, we performed the following **data preprocessing** steps: \n",
    "- All text was converted to lowercase, except for App names, such as Facebook, Instagram, Threads...\n",
    "- Irrelevant characters were removed ('--')\n",
    "- Short sentences were removed to provide meaningful insights (less than 8 words), which was done in the text extraction step\n",
    "- All text was then normalized to its original form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Large Language Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def data_preprocess_pipeline_llm(text):\n",
    "    # Normalize Unicode characters\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "\n",
    "    # Replace multiple dashes with a space\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "\n",
    "    # Run spaCy NLP pipeline\n",
    "    doc = nlp(text)\n",
    "        \n",
    "    # Keep all tokens except spaces\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_space]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data-preprocessing pipeline\n",
    "df_llm['sentence'] = df_llm['sentence'].apply(data_preprocess_pipeline_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Q&A section only\n",
    "df1 = df_llm[df_llm['section'] == 'Q&A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"df1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FinBERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For FinBERT model, we performed:\n",
    "-  Stopword removal.\n",
    "- Remove commas: In long and complex sentences, different parts of the sentence may be separated by commas.In some cases, these commas are followed by the main verb or conjunction. We remove these commas to simply the sentence structure and improve the accuracy of the model, especially when the conjunction is the starting point of a contrasting argument.\n",
    "- Sentiment focus: Complex sentences often key words such as 'but','while', 'partially' ... In these sentences, there are mixed sentiment. However, it is clear that the main sentiment lies in the second part of the sentence that follows these key words. Therefore, we apply the sentiment focus to shift the emphasis of a sentence based on these keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def data_preprocess_pipeline_finbert(text):\n",
    "    text = unicodedata.normalize('NFKC', text) \n",
    "    # Remove special characters '--' in the earnings call transcripts\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    # Remove stop words\n",
    "    for token in doc:\n",
    "        if not token.is_stop:\n",
    "            tokens.append(token.text)\n",
    "            \n",
    "    # Next, we will perform text normalization and lowercase conversion only for words that are not named entities\n",
    "    # Name-entity recognition \n",
    "    for token in doc:\n",
    "        if token.ent_type_:\n",
    "            tokens.append(token.text)\n",
    "        else:\n",
    "            # Text normalization (lemmatization) \n",
    "            lemmatization = token.lemma_\n",
    "            # Convert to lowercase\n",
    "            tokens.append(lemmatization.lower())\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data-preprocessing pipeline\n",
    "df_finbert['sentence'] = df_finbert['sentence'].apply(data_preprocess_pipeline_finbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas\n",
    "def remove_commas_spacy(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    doc = nlp(text)\n",
    "\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        # Skip commas that are punctuation\n",
    "        if token.text == ',' and token.dep_ == \"punct\":\n",
    "            continue\n",
    "        filtered_tokens.append(token)\n",
    "\n",
    "    # Rebuild text with spaces between tokens except when punctuation directly follows a word\n",
    "    new_text = \"\"\n",
    "    for i, token in enumerate(filtered_tokens):\n",
    "        new_text += token.text\n",
    "        # Add a space if:\n",
    "        # - this token is not the last token\n",
    "        # - and the next token is NOT punctuation (so words get separated)\n",
    "        if i < len(filtered_tokens) - 1:\n",
    "            next_token = filtered_tokens[i+1]\n",
    "            if not next_token.is_punct:\n",
    "                new_text += \" \"\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply removing commas\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "df_finbert[\"sentence\"] = df_finbert[\"sentence\"].progress_apply(remove_commas_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_focus(text):\n",
    "    doc = nlp(text)\n",
    "    focus = \"\"\n",
    "    focus_changed = 1\n",
    "    # For sentences containing 'but', we focus on the part after 'but'\n",
    "    for token in doc[:-1]:\n",
    "      if token.lower_ == \"but\":\n",
    "          focus = doc[token.i + 1:]\n",
    "          return str(focus).strip(),focus_changed\n",
    "        \n",
    "    # For sentences containing 'partially offset', we focus on the part before 'partially'\n",
    "    for token in doc:\n",
    "      if token.lower_ == \"partially\":\n",
    "           focus = doc[:token.i].text\n",
    "           return str(focus).strip(), focus_changed\n",
    "\n",
    "    if doc[0].lower_ == \"while\":\n",
    "      try:\n",
    "        comma_index_back1 = [token2.i for token2 in doc if token2.text == ','][0]\n",
    "      except IndexError:\n",
    "        return str(doc).strip(),focus_changed\n",
    "      focus = doc[comma_index_back1+1:].text\n",
    "      return str(focus).strip(),focus_changed\n",
    "\n",
    "    focus_changed = 0\n",
    "    return str(doc).strip(),focus_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment focus\n",
    "df_finbert[['sentence_simple', 'focus_changed']] = df_finbert['sentence'].progress_apply(sentiment_focus).apply(pd.Series)\n",
    "\n",
    "df_finbert['focus_ornot'] = df_finbert['focus_changed'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "df_finbert.drop('focus_changed', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to Q&A section only\n",
    "df_finbert = df_finbert[df_finbert['section'] == 'Q&A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finbert.to_csv(\"df_finbert.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smm768",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
